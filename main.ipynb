{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from scripts.target_scripts import (\n",
    "    assign_features_ks_hours,\n",
    "    prepare_shift_and_lags,\n",
    "    prepare_target_set,\n",
    ")\n",
    "\n",
    "\n",
    "def create_datasets():\n",
    "    \"\"\"\n",
    "    Функция создания датасета\n",
    "    Проходимся по Target_Name (названия КС в формате \"КС-15\"), вложенный цикл по сдвигам дней (48, 72, 96),\n",
    "    вложенный цикл по направлению давления (входное/выходное - \"Pin\"/\"Pout\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #! DEBUG  измени перед релизом\n",
    "    print(\"HI\")\n",
    "    for Target_Name in [ \"КС-16\"]:\n",
    "        # for Target_Name in [\"КС-15\"]:\n",
    "        for Hours in [48]:\n",
    "            # for Hours in [48]:\n",
    "            Target_List = [\"КС-15\", \"КС-16\", \"КС-17\", \"КС-19\"]\n",
    "            for mode in [\"Pin\"]:\n",
    "                try:\n",
    "                    # for mode in [\"Pin\"]:\n",
    "                    # t_set = prepare_dataset(Target_List, Target_Name, \"2\",hours= Hours) #* В папке upload должны будут лежать\n",
    "\n",
    "                    try:\n",
    "                        t_set = pd.read_excel(\n",
    "                            \"uploaded/\"\n",
    "                            + Target_Name\n",
    "                            + \"_\"\n",
    "                            + mode\n",
    "                            + \"_\"\n",
    "                            + str(Hours)\n",
    "                            + \"_h.xlsx\"\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        raise Exception(e)\n",
    "\n",
    "                    # ! DEBUG\n",
    "                    # try:\n",
    "                    #     weather_dfs = prepare_weather_dict_dataset()\n",
    "\n",
    "                    # except Exception as e:\n",
    "                    #     raise(Exception\"Prepare weather dict error:\\n\"+e)\n",
    "\n",
    "                    try:\n",
    "                        result = prepare_target_set(t_set, [])  #! DEBUG\n",
    "                    except Exception as e:\n",
    "                        raise Exception(\"Prepare target set error:\\n\")\n",
    "\n",
    "                    try:\n",
    "                        total_result = prepare_shift_and_lags(result)\n",
    "                    except Exception as e:\n",
    "                        raise Exception(\"Prapare shift and lags error:\\n\")\n",
    "\n",
    "                    try:\n",
    "                        total_result_new = total_result.rename(\n",
    "                            columns=lambda x: re.sub(\"[^A-Za-z0-9_]+\", \"_\", x)\n",
    "                        )\n",
    "                        new_names = {\n",
    "                            col: re.sub(r\"[^A-Za-zА-Яа-я0-9_]+\", \"\", col)\n",
    "                            for col in total_result.columns\n",
    "                        }\n",
    "                        new_n_list = list(new_names.values())\n",
    "                        # [LightGBM] Исправление одинаковых колонок.\n",
    "                        new_names = {\n",
    "                            col: (\n",
    "                                f\"{new_col}_{i}\"\n",
    "                                if new_col in new_n_list[:i]\n",
    "                                else new_col\n",
    "                            )\n",
    "                            for i, (col, new_col) in enumerate(new_names.items())\n",
    "                        }\n",
    "                        total_result_new = total_result.rename(columns=new_names)\n",
    "                    except Exception as e:\n",
    "                        raise Exception(\"Rename columns error:\\n\")\n",
    "\n",
    "                    try:\n",
    "                        train_set_column_names = (\n",
    "                            pd.read_parquet(\n",
    "                                \"data/test_set_КС-16_Pin_48_h.parquet\"\n",
    "                            )\n",
    "                            .rename(\n",
    "                                columns={\n",
    "                                    f\"{mode}_target_shift_{Hours}h_{Target_Name[-2:]}\": f\"{mode}_target_shift_{Hours}h_КС{Target_Name[-2:]}\"\n",
    "                                },\n",
    "                            )\n",
    "                            .columns\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        raise Exception(\n",
    "                            \"Error getting columns names from train dataset:\\n\"\n",
    "                        )\n",
    "\n",
    "                    try:\n",
    "                        result_final = assign_features_ks_hours(\n",
    "                            total_result_new,\n",
    "                            train_set_column_names,\n",
    "                            mode,\n",
    "                            Target_Name[-2:],\n",
    "                            Hours,\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "                    try:\n",
    "                        result_final.to_parquet(\n",
    "                            \"data/\"\n",
    "                            + Target_Name\n",
    "                            + \"_\"\n",
    "                            + mode\n",
    "                            + \"_\"\n",
    "                            + str(Hours)\n",
    "                            + \"_h_new.parquet\",\n",
    "                            index=None,\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_Name = \"КС-16\"\n",
    "mode = \"Pin\"\n",
    "Hours = \"48h\"\n",
    "\n",
    "df = (\n",
    "    pd.read_parquet(\"data/test_set_КС-16_Pin_48_h.parquet\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            f\"{mode}_target_shift_{Hours}h_{Target_Name[-2:]}\": f\"{mode}_target_shift_{Hours}h_КС{Target_Name[-2:]}\"\n",
    "        },\n",
    "    )\n",
    "    .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the Parquet files\n",
    "input_directory = \"./buffer\"\n",
    "output_directory = \"./uploaded\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    print(\"hi\")\n",
    "    if filename.endswith(\".parquet\") and filename.startswith(\"КС-16\") :\n",
    "        \n",
    "        # Full path to the input Parquet file\n",
    "        parquet_file = os.path.join(input_directory, filename)\n",
    "\n",
    "        # Read the Parquet file into a DataFrame\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "\n",
    "        # Define the output Excel file name\n",
    "        excel_file = os.path.join(\n",
    "            output_directory, f\"{os.path.splitext(filename)[0]}.xlsx\"\n",
    "        )\n",
    "\n",
    "        # Write the DataFrame to an Excel file\n",
    "        df.to_excel(excel_file, index=False)\n",
    "\n",
    "        print(f\"Converted {filename} to {os.path.basename(excel_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "КС 16\n",
    "Hours 48h\n",
    "Pmode оба"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    ks: str,\n",
    "    pmode: str,\n",
    "    hours: str,\n",
    "    date: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    KC - номер КС (15, 16, 17, 19 и тд)\n",
    "    Pmode - Pin/Pout\n",
    "    Hours - 48h, 72h, 96h\n",
    "    date - дата, дд.мм.гггг\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model_path = f\"ModelsNewFix/{pmode}_lag_{hours}_КС-{ks}_LGBM_model.joblib\"\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    # Load training and test data\n",
    "    train_path = f\"data/train_set_КС-{ks}_{pmode}_{hours[:-1]}_h.parquet\"\n",
    "    test_path = f\"data/test_set_КС-{ks}_{pmode}_{hours[:-1]}_h.parquet\"\n",
    "    train = pd.read_parquet(train_path).rename({f\"{pmode}_target_shift_{hours}_{ks}\" : f\"{pmode}_target_shift_{hours}_КС{ks}\"})\n",
    "    test = pd.read_parquet(test_path).rename({f\"{pmode}_target_shift_{hours}_{ks}\" : f\"{pmode}_target_shift_{hours}_КС{ks}\"})\n",
    "    # Filter test data by date\n",
    "    test = test[test[\"DateTime\"].dt.strftime(\"%d.%m.%Y\") == date]\n",
    "    if len(test) == 0:\n",
    "        test = train[train[\"DateTime\"].dt.strftime(\"%d.%m.%Y\") == date]\n",
    "        if len(test) == 0:\n",
    "            raise Exception(\"Error\")\n",
    "    # Prepare training data\n",
    "    X_train = train.drop(columns=[\"DateTime\", f\"{pmode}_target_shift_{hours}_КС{ks}\"])\n",
    "    y_train = train[f\"{pmode}_target_shift_{hours}_КС{ks}\"]\n",
    "    # Fit the model\n",
    "    loaded_model.fit(X_train, y_train)\n",
    "    # Prepare test data\n",
    "    X_test = test.drop(columns=[\"DateTime\"])\n",
    "    # Create date index for the predictions\n",
    "    date_index = test[\"DateTime\"].apply(\n",
    "        lambda x: x + pd.Timedelta(hours=int(hours[:-1]))\n",
    "    )\n",
    "    date_index = pd.to_datetime(date_index, errors=\"coerce\").dt.strftime(\n",
    "        \"%Y-%m-%d %H:%M\"\n",
    "    )\n",
    "    # Make predictions\n",
    "    result = loaded_model.predict(X_test)\n",
    "    prediction = pd.concat(\n",
    "        [\n",
    "            date_index.reset_index(drop=True),\n",
    "            pd.DataFrame(result).apply(lambda x: round(x, 3)),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).rename(columns={0: \"Result\"})\n",
    "    # Add additional fields\n",
    "    # prediction[\"mode\"] = pmode\n",
    "    # prediction[\"station\"] = ks\n",
    "    # Save prediction to Excel\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"inspect/Object.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "start_date = datetime.strptime('03.01.2021', '%d.%m.%Y')\n",
    "end_date = datetime.strptime('21.01.2024', '%d.%m.%Y')\n",
    "best_day = start_date\n",
    "best_score = 10000\n",
    "# Iterate over the range of dates\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "\n",
    "        result = predict(\"16\",\"Pin\",\"48h\",(current_date - timedelta(days=2)).strftime('%d.%m.%Y'))\n",
    "        result[\"DateTime\"] = pd.to_datetime(result[\"DateTime\"])\n",
    "        y_pred = result[result[\"DateTime\"].dt.strftime(\"%d.%m.%Y\") == current_date.strftime(\"%d.%m.%Y\")][\"Result\"]\n",
    "        # df[df[\"Data\"].dt.strftime(\"%d.%m.%Y %H:%M\") == (current_date + timedelta(hours=1)).strftime(\"%d.%m.%Y %H:%M\")][df[\"Object\"] == 1][\"P_Plan\"]\n",
    "        y_true = df[df[\"Data\"].dt.strftime(\"%d.%m.%Y\") == current_date.strftime(\"%d.%m.%Y\")][df[\"Object\"] == 2][\"P_Fact\"]\n",
    "        y_true = df[df[\"Data\"].dt.strftime(\"%d.%m.%Y\") == current_date.strftime(\"%d.%m.%Y\")][df[\"Object\"] == 2][\"P_Plan\"]\n",
    "        mae_result = mean_absolute_error(y_true, y_pred)\n",
    "        if mae_result < best_score:\n",
    "            best_score = mae_result\n",
    "            best_day = current_date\n",
    "        current_date += timedelta(days=1)\n",
    "        # mae_result = mean_absolute_error(y_true, y_pred)\n",
    "print({\"mae\": mae_result, \"model\": y_pred, \"fact\": y_true})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly #for plotting\n",
    "from plotly import graph_objects as go\n",
    "from plotly import express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=roll_list[\"time\"], y=roll_list['STAND2_RGH_SRV'], name=\"Позиция сервоклапана правой капсулы, %\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=roll_list[\"time\"], y=roll_list['STAND2_RGH_SRV_REF'], name=\"Задание на сервоклапан правой капсулы, %\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=roll_list[\"time\"], y=roll_list['STAND2_RGH_SRV_REF'], name=\"Задание на сервоклапан правой капсулы, %\"))\n",
    "\n",
    "fig.update_layout(\n",
    "\n",
    "    title=dict(text=\"MAE Pin model= plan=\", font=dict(size=18), automargin=True, yref='paper')\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_results_for_date(object_id:str,ks:str, pmode:str, hours:str, date_str: str):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ks - номер КС (15, 16, 17, 19 и тд)\n",
    "    pmode - Pin/Pout\n",
    "    hours - 48h, 72h, 96h\n",
    "    date_str - дата\n",
    "    \"\"\"\n",
    "    #* Открываем заготовленный план-факт\n",
    "    df = pd.read_csv(\"inspect/P_in_Plan_Fact.csv\", delimiter=\";\")\n",
    "    df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n",
    "    date = datetime.strptime(date_str, \"%d.%m.%Y\")\n",
    "    result = predict(ks, pmode, hours, (date - timedelta(days=2)).strftime(\"%d.%m.%Y\"))\n",
    "    result[\"DateTime\"] = pd.to_datetime(result[\"DateTime\"])\n",
    "    y_pred = result[\n",
    "        result[\"DateTime\"].dt.strftime(\"%d.%m.%Y\") == date.strftime(\"%d.%m.%Y\")\n",
    "    ][\"Result\"]\n",
    "    # df[df[\"Data\"].dt.strftime(\"%d.%m.%Y %H:%M\") == (current_date + timedelta(hours=1)).strftime(\"%d.%m.%Y %H:%M\")][df[\"Object\"] == 1][\"P_Plan\"]\n",
    "    y_true = df[df[\"Data\"].dt.strftime(\"%d.%m.%Y\") == date.strftime(\"%d.%m.%Y\")][\n",
    "        df[\"Object\"] == 1\n",
    "    ][\"P_Fact\"]\n",
    "    mae_result = mean_absolute_error(y_true, y_pred)\n",
    "    return {\"mae\": mae_result, \"model\": y_pred, \"fact\": y_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_series_results_for_date(\"1\",\"15\", \"Pin\", \"48h\", \"03.01.2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_result(object_id:str,ks:str, pmode:str, hours:str, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ks - номер КС (15, 16, 17, 19 и тд)\n",
    "    pmode - Pin/Pout\n",
    "    hours - 48h, 72h, 96h\n",
    "    start_date - начальная дата 03.01.2021\n",
    "    end_date - конечная дата 21.01.2021\n",
    "    \"\"\"\n",
    "    # start_date = datetime.strptime('03.01.2021', '%d.%m.%Y')\n",
    "    # end_date = datetime.strptime('21.01.2021', '%d.%m.%Y')\n",
    "    best_day = start_date\n",
    "    best_score = 10000\n",
    "    # Iterate over the range of dates\n",
    "    try:\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            df = pd.read_csv(\"inspect/P_in_Plan_Fact.csv\", delimiter=\";\")\n",
    "            df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n",
    "            if mae_result < best_score:\n",
    "                    best_score = mae_result\n",
    "                    best_day = current_date\n",
    "            current_date += timedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка в значениях: \",e)\n",
    "        print(\"Цикл завершен\")\n",
    "    return best_day, best_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
